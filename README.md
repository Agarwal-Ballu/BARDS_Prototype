### Boosted AI-Driven Refactoring System (Hybrid Python Code Generator & Debugger)
This repository contains the **backend service** for **BADRS**, a hybrid AI system that powers a **VS Code extension** for **Python code generation, debugging, refactoring, and evaluation**.
The backend runs **locally** using **FastAPI** and combines:

* **Gemini (Cloud LLM)** â†’ reasoning, planning, validation
* **CodeLlama (via Ollama, Local LLM)** â†’ final Python code generation

ğŸ” **No API keys are hard-coded** â€” all secrets are managed via environment variables.

---

## ğŸš€ Key Features

âœ… Hybrid LLM pipeline (Gemini + CodeLlama)
âœ… Python-only code generation & debugging
âœ… Optional auto-test generation
âœ… AI accuracy scoring
âœ… Guardrails to reject non-Python prompts
âœ… Safe fallback when Gemini quota fails
âœ… Environment-based secret management
âœ… FastAPI + async execution
âœ… Seamless VS Code extension integration

---

## ğŸ§  Hybrid AI Flow

```
User Prompt
   â†“
Language Guard (Python only)
   â†“
Gemini (Planning / Validation)
   â†“ (fallback if quota fails)
CodeLlama via Ollama (Local Code Generation)
   â†“
Accuracy Scoring
   â†“
VS Code Extension Output
```

---

## ğŸ“¦ Project Components

### 1ï¸âƒ£ Backend (FastAPI)

* Handles prompt processing
* Runs hybrid LLM logic
* Scores output accuracy
* Enforces Python guardrails

### 2ï¸âƒ£ VS Code Extension

* Sends selected code/prompts to backend
* Inserts generated code into editor
* Displays AI accuracy score
* Works fully locally

---

## ğŸ§° Prerequisites

Make sure you have the following installed:

* **Python 3.9+**
* **Ollama**
* **CodeLlama model**
* **Gemini API Key**
* **VS Code (for extension usage)**

---

## ğŸ¦™ Ollama Installation & Setup

### Install Ollama

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

### Pull CodeLlama Model

```bash
ollama pull codellama:7b-instruct-q4_0
```

### Verify Ollama is Running

```bash
ollama list
```

Ollama API runs locally at:

```
http://127.0.0.1:11434
```

---

## ğŸŒ (Optional) Expose Ollama via Ngrok

Useful if Gemini or other services need remote access.

### Install pyngrok

```bash
pip install pyngrok
```

### Start Ngrok Tunnel

```python
from pyngrok import ngrok

ngrok.set_auth_token("<YOUR_NGROK_AUTH_TOKEN>")

public_url = ngrok.connect(11434, host_header="localhost:11434")
print("Public Ollama URL:", public_url.public_url)
```

---

## ğŸ”— Query Ollama Programmatically

```python
import requests

def query_ollama(prompt, model="codellama:7b-instruct-q4_0"):
    url = "http://127.0.0.1:11434/api/generate"
    payload = {
        "model": model,
        "prompt": prompt,
        "stream": False
    }
    response = requests.post(url, json=payload)
    return response.json().get("response", "")
```

---

## ğŸ” Environment Configuration

Create a `.env` file inside `backend/`:

```env
GEMINI_API_KEY=your_gemini_api_key_here
OLLAMA_BASE_URL=http://127.0.0.1:11434
```

ğŸ“Œ `.env` is ignored by Git (`.env.example` is provided).

---

## âš™ï¸ Backend Installation

```bash
cd backend
python -m venv venv
source venv/bin/activate        # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

---

## â–¶ï¸ Run the Backend Server

```bash
uvicorn app.main:app --reload
```

### API Docs

```
http://127.0.0.1:8000/docs
```

---

## ğŸ§© VS Code Extension Usage

1. Install the `.vsix` extension
2. Open a Python file
3. Select code or place cursor on a line
4. Press:

```
Ctrl + Shift + P â†’ Run Hybrid Python AI
```

The extension will:

* Generate or debug Python code
* Insert output directly into editor
* Show AI accuracy score

---

## ğŸ›¡ï¸ Guardrails & Safety

âœ”ï¸ Only Python-related prompts allowed
âŒ Non-Python questions rejected
âŒ Unwanted explanations removed
âœ”ï¸ Code-only output when required
âœ”ï¸ Automatic fallback to CodeLlama if Gemini fails

Example rejection message:

> *â€œAww, thanks for asking! ğŸ˜Š
> Iâ€™m built to generate and debug Python code ğŸ
> Please try a Python-related question.â€*

---

## ğŸ“Š Accuracy Scoring

Heuristic scoring based on:

* Structure validity
* Return correctness
* Logic completeness
* Test alignment (if enabled)

Score range: **0â€“100%**

---

## ğŸš€ Why BARDS?

Most AI coding tools:

* âŒ Use only one model
* âŒ Leak API keys
* âŒ Break when quota fails

**BARDS is different:**

* âœ… Hybrid & fault-tolerant
* âœ… Local + cloud
* âœ… Secure by design
* âœ… Built for real developers

---

## ğŸ“œ License

MIT License â€” free to use, modify, and distribute.

---

## ğŸ”® Future Roadmap

The current version of **BARDS** focuses on leveraging powerful pre-trained models (Gemini + CodeLlama).
Future updates aim to **eliminate the core limitations of general-purpose LLMs** and move towards a **lean, highly optimized, developer-first AI system**.

### ğŸš§ Planned Enhancements

#### 1ï¸âƒ£ Hybrid Fine-Tuned Open-Source Models

* Train and fine-tune **smaller open-source models** specifically for:

  * Python code generation
  * Debugging and refactoring
  * Algorithmic optimization
* Combine multiple specialized models into a **hybrid ensemble** where each model compensates for the weaknesses of others.

#### 2ï¸âƒ£ Accuracy-First Code Generation

* Focus on producing **logically correct, edge-case-safe code** rather than verbose outputs.
* Automatic optimization for:

  * **Time complexity**
  * **Space complexity**
* Preference for clean, readable, and production-ready code.

#### 3ï¸âƒ£ Intelligent Model Selection

* Dynamically select the best model based on:

  * Problem type (DSA, scripting, debugging, refactoring)
  * Code size and complexity
  * Performance constraints
* Reduce unnecessary token usage and hallucinations.

#### 4ï¸âƒ£ Cost-Free & Local-First AI

* Reduce dependency on paid APIs.
* Enable **fully local execution** using fine-tuned lightweight models.
* Ensure high-quality results without subscription-based limitations.

#### 5ï¸âƒ£ Continuous Self-Improvement Loop

* Use evaluation feedback, test results, and accuracy scores to:

  * Improve model routing logic
  * Identify recurring failure patterns
  * Continuously refine responses

#### 6ï¸âƒ£ Competitive Alternative to Paid AI Tools

* Deliver **high-quality, optimized code** comparable to premium AI tools.
* Zero or minimal operational cost.
* Transparent, open, and developer-controlled architecture.

---

### ğŸ¯ Long-Term Vision

> To build a **cost-efficient, high-accuracy, developer-grade AI system**
> that generates **optimized, reliable, and minimal Python code**,
> making advanced AI coding assistance accessible to everyone â€”
> **without locking users behind expensive subscriptions.**

---

## ğŸ‘¤ Author

**Balram Agarwal**

Python â€¢ AI â€¢ Computer Science Engineering

